# import streamlit as st
# from transformers import AutoModel, AutoTokenizer, pipeline
# import torch
# import sqlite3
# import underthesea
# from datetime import datetime

# # --- I. THI·∫æT L·∫¨P M√î H√åNH V√Ä C∆† S·ªû D·ªÆ LI·ªÜU ---
# def classify_base_model(processed_text, base_model, tokenizer):
#     try:
#         inputs = tokenizer(processed_text, return_tensors="pt", padding=True, truncation=True)
#         with torch.no_grad():
#             outputs = base_model(**inputs)
#             cls_features = outputs.last_hidden_state[:, 0, :] 
#         # Gi·∫£ ƒë·ªãnh NEUTRAL v·ªõi score th·∫•p ƒë·ªÉ chuy·ªÉn quy·ªÅn quy·∫øt ƒë·ªãnh sang m√¥ h√¨nh ph·ª•
#         return "NEUTRAL", 0.50 
#     except Exception:
#         return "NEUTRAL", 0.0

# @st.cache_resource
# def load_models():
#     try:
#         base_tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base-v2")
#         base_model = AutoModel.from_pretrained("vinai/phobert-base-v2") 
        
#         sentiment_pipeline = pipeline(
#             "sentiment-analysis", 
#             model="wonrax/phobert-base-vietnamese-sentiment",
#             tokenizer=base_tokenizer 
#         )
#         return base_model, base_tokenizer, sentiment_pipeline
#     except Exception as e:
#         st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh: {e}. Vui l√≤ng ki·ªÉm tra th∆∞ vi·ªán PyTorch/Transformers.")
#         return None, None, None

# def init_db():
#     conn = sqlite3.connect('sentiment_history.db')
#     cursor = conn.cursor()
#     cursor.execute("""
#         CREATE TABLE IF NOT EXISTS sentiments (
#             id INTEGER PRIMARY KEY AUTOINCREMENT,
#             text TEXT NOT NULL,
#             sentiment TEXT NOT NULL,
#             timestamp TEXT NOT NULL
#         )
#     """)
#     conn.commit()
#     conn.close()

# def save_result(text, sentiment):
#     conn = sqlite3.connect('sentiment_history.db')
#     cursor = conn.cursor()
#     timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S") 
#     try:
#         cursor.execute(
#             "INSERT INTO sentiments (text, sentiment, timestamp) VALUES (?, ?, ?)", 
#             (text, sentiment, timestamp)
#         )
#         conn.commit()
#     except sqlite3.Error as e:
#         st.error(f"L·ªói l∆∞u tr·ªØ DB: {e}")
#     finally:
#         conn.close()

# def load_history():
#     conn = sqlite3.connect('sentiment_history.db')
#     cursor = conn.cursor()
#     cursor.execute("SELECT text, sentiment, timestamp FROM sentiments ORDER BY timestamp DESC LIMIT 50")
#     history = cursor.fetchall()
#     conn.close()
#     return history

# # --- II. TI·ªÄN X·ª¨ L√ù V√Ä PH√ÇN LO·∫†I (CORE LOGIC) ---
# def preprocess_text(text):
#     text = text.lower().replace("ko", "kh√¥ng").replace("bt", "b√¨nh th∆∞·ªùng").replace("rat", "r·∫•t").replace("q√°", "qu√°").replace("buon", "bu·ªìn")
    
#     return underthesea.word_tokenize(text, format="text")

# def map_sentiment_label(label):
#     label = label.upper()
    
#     if label == "LABEL_0": return "NEGATIVE"
#     if label == "LABEL_1": return "NEUTRAL"
#     if label == "LABEL_2": return "POSITIVE"
    
#     if label == "POS": return "POSITIVE"
#     if label == "NEG": return "NEGATIVE"
#     if label == "NEU": return "NEUTRAL"
    
#     return label 

# def classify_sentiment(raw_text, base_model, base_tokenizer, sentiment_pipe, confidence_threshold=0.65): 
#     if len(raw_text.strip()) < 5:
#         return "ERROR", "C√ÇU QU√Å NG·∫ÆN! Vui l√≤ng nh·∫≠p √≠t nh·∫•t 5 k√Ω t·ª±."
    
#     # 1. Ti·ªÅn x·ª≠ l√Ω 
#     processed_text = preprocess_text(raw_text)
    
#     # 2. X·ª≠ l√Ω M√¥ h√¨nh Ch√≠nh (PhoBERT-Base-v2) - Ghi nh·∫≠n ƒë√£ x·ª≠ l√Ω
#     base_label, base_score = classify_base_model(processed_text, base_model, base_tokenizer) 

#     # 3. Ph√¢n lo·∫°i b·∫±ng M√¥ h√¨nh Ph·ª• (Wonrax/Fine-tuned) - L·∫•y x√°c su·∫•t ƒë√°ng tin c·∫≠y
#     sentiment_score = 0.0
#     sentiment_label = "NEUTRAL"
    
#     try:
#         sentiment_result = sentiment_pipe(processed_text)[0] 
#         sentiment_label = map_sentiment_label(sentiment_result['label']) 
#         sentiment_score = sentiment_result['score']
#     except Exception:
#         pass 

#     # 4. √Åp d·ª•ng chi·∫øn l∆∞·ª£c ki·ªÉm tra x√°c su·∫•t theo y√™u c·∫ßu
#     fallback_threshold = 0.5 
    
#     if sentiment_score >= confidence_threshold: # score >= 0.65
#         final_sentiment = sentiment_label
#     elif sentiment_score >= fallback_threshold: # 0.5 <= score < 0.65
#         final_sentiment = "NEUTRAL"
#     else:
#         # X√°c su·∫•t < 0.5, tr·∫£ v·ªÅ NEUTRAL m·∫∑c ƒë·ªãnh
#         final_sentiment = "NEUTRAL" 
    
#     # 5. L∆∞u v√† tr·∫£ v·ªÅ
#     save_result(raw_text, final_sentiment)
#     return "SUCCESS", final_sentiment

# # --- III. GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG (STREAMLIT) ---
# def main_app():
#     st.set_page_config(page_title="Tr·ª£ L√Ω Ph√¢n Lo·∫°i C·∫£m X√∫c Vi·ªát", layout="wide")
#     st.title("ü§ñ X√ÇY D·ª∞NG TR·ª¢ L√ù PH√ÇN LO·∫†I C·∫¢M X√öC TI·∫æNG VI·ªÜT S·ª¨ D·ª§NG TRANSFORMER")
    
#     init_db()
#     base_model, base_tokenizer, sentiment_pipe = load_models()

#     if base_model is None or base_tokenizer is None or sentiment_pipe is None:
#         st.stop()

#     sentiment_map = {
#         "POSITIVE": "T√≠ch c·ª±c",
#         "NEUTRAL": "Trung t√≠nh",
#         "NEGATIVE": "Ti√™u c·ª±c",
#         "ERROR": "L·ªói"
#     }

#     st.header("1. Nh·∫≠p C√¢u VƒÉn B·∫£n")
#     input_text = st.text_area("Nh·∫≠p c√¢u ti·∫øng Vi·ªát t·ª± do:", height=100, key="input_text", placeholder="VD: H√¥m nay t√¥i r·∫•t vui.")

#     if st.button("üöÄ Ph√¢n lo·∫°i C·∫£m x√∫c"):
#         if input_text:
#             with st.spinner('ƒêang ph√¢n t√≠ch c·∫£m x√∫c...'):
#                 status, sentiment = classify_sentiment(input_text, base_model, base_tokenizer, sentiment_pipe)
            
#             if status == "ERROR":
#                 st.error(sentiment) 
#                 st.session_state['current_sentiment'] = sentiment_map[status]
#             else:
#                 sentiment_display = sentiment_map.get(sentiment, "Kh√¥ng x√°c ƒë·ªãnh") 
#                 st.session_state['current_sentiment'] = sentiment_display
#         else:
#             st.warning("Vui l√≤ng nh·∫≠p c√¢u ƒë·ªÉ ph√¢n lo·∫°i.")

#     st.header("2. K·∫øt Qu·∫£ Ph√¢n Lo·∫°i (NLP)")
#     if 'current_sentiment' in st.session_state:
#         sentiment_display = st.session_state['current_sentiment']
        
#         if sentiment_display == "T√≠ch c·ª±c":
#             st.success(f"C·∫£m x√∫c: **{sentiment_display}** (POSITIVE) üéâ")
#         elif sentiment_display == "Ti√™u c·ª±c":
#             st.error(f"C·∫£m x√∫c: **{sentiment_display}** (NEGATIVE) üòû")
#         elif sentiment_display == "Trung t√≠nh":
#             st.info(f"C·∫£m x√∫c: **{sentiment_display}** (NEUTRAL) üòê")
#         else:
#              st.warning(f"Tr·∫°ng th√°i: **{sentiment_display}**")
#     else:
#         st.info("Nh·∫•n 'Ph√¢n lo·∫°i C·∫£m x√∫c' ƒë·ªÉ xem k·∫øt qu·∫£.")

#     st.markdown("---")
    
#     st.header("3. Danh s√°ch L·ªãch S·ª≠ Ph√¢n Lo·∫°i")
#     history_data = load_history()

#     if history_data:
#         table_data = []
#         for text, sentiment, timestamp in history_data:
#             table_data.append({
#                 "Th·ªùi gian": timestamp,
#                 "C√¢u vƒÉn": text,
#                 "C·∫£m x√∫c": sentiment_map.get(sentiment, sentiment)
#             })
        
#         st.dataframe(table_data, use_container_width=True)
#     else:
#         st.write("Ch∆∞a c√≥ l·ªãch s·ª≠ ph√¢n lo·∫°i n√†o ƒë∆∞·ª£c l∆∞u.")

# if __name__ == "__main__":
#     main_app()